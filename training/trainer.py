"""
üèãÔ∏è‚Äç‚ôÇÔ∏è –¢–†–ï–ù–ï–† –ú–û–î–ï–õ–ò - –ü–û–õ–ù–´–ô –ì–ò–ë–ö–ò–ô –ö–û–î
====================================

–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≥–∏–±–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è —Å:
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ early stopping
- –ü–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä–∞–∑–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ –∏ schedulers  
- –ì–∏–±–∫–∏–º–∏ callbacks –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏
"""

import torch
import torch.nn as nn
from torch.optim import Optimizer
from torch.optim.lr_scheduler import _LRScheduler
import numpy as np
import time
from typing import Dict, Any, List, Optional, Callable, Union, Tuple
from pathlib import Path
import json

# üîß –ë–ï–ó–û–ü–ê–°–ù–´–ï –ò–ú–ü–û–†–¢–´
import sys
import os
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from utils.config import ModelConfig
    from utils.data_utils import get_batch
    from utils.logging import GenerationLogger
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –≤ trainer: {e}")
    sys.exit(1)


@torch.no_grad()
def estimate_loss(model: nn.Module, 
                  data: torch.Tensor, 
                  config: ModelConfig,
                  splits: List[str] = None) -> Dict[str, torch.Tensor]:
    """
    üìä –û–¶–ï–ù–ö–ê LOSS

    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç loss –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏

    Args:
        model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        splits: –°–ø–∏—Å–æ–∫ —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ ['train', 'val', 'test']

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å loss –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
    """
    if splits is None:
        splits = ['train', 'val']

    out = {}
    model.eval()

    for split in splits:
        losses = torch.zeros(config.eval_iters, device=config.device)

        for k in range(config.eval_iters):
            try:
                X, y = get_batch(data, config, split)
                logits, loss = model(X, y)
                losses[k] = loss.item()
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–∞—Ç—á–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ
                losses[k] = losses[:k].mean() if k > 0 else torch.tensor(float('inf'))
                break

        out[split] = losses.mean()

    model.train()
    return out


def calculate_perplexity(loss: float) -> float:
    """üìè –†–∞—Å—á–µ—Ç perplexity –∏–∑ loss"""
    return torch.exp(torch.tensor(loss)).item()


def calculate_tokens_per_second(tokens_processed: int, elapsed_time: float) -> float:
    """‚ö° –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤"""
    return tokens_processed / elapsed_time if elapsed_time > 0 else 0.0


class EarlyStopping:
    """
    ‚èπÔ∏è –ü–†–û–î–í–ò–ù–£–¢–´–ô EARLY STOPPING

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏:
    - –ü–æ validation loss
    - –ü–æ overfit –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—É  
    - –ü–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—é —É–ª—É—á—à–µ–Ω–∏–π –∑–∞ N —ç–ø–æ—Ö
    """

    def __init__(self, 
                 patience: int = 5,
                 min_delta: float = 0.001,
                 mode: str = 'min',
                 restore_best_weights: bool = True):
        """
        Args:
            patience: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è
            min_delta: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–ª—è —Å—á–∏—Ç–∞—é—â–µ–≥–æ—Å—è —É–ª—É—á—à–µ–Ω–∏–µ–º
            mode: 'min' –¥–ª—è loss, 'max' –¥–ª—è accuracy
            restore_best_weights: –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –ª—É—á—à–∏–µ –≤–µ—Å–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.restore_best_weights = restore_best_weights

        self.best_score = None
        self.counter = 0
        self.best_weights = None
        self.early_stop = False

        self.compare = np.less if mode == 'min' else np.greater
        self.min_delta *= -1 if mode == 'min' else 1

    def __call__(self, score: float, model: nn.Module) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è early stopping

        Args:
            score: –¢–µ–∫—É—â–∞—è –º–µ—Ç—Ä–∏–∫–∞ (loss –∏–ª–∏ accuracy)
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤

        Returns:
            bool: True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ
        """
        if self.best_score is None:
            self.best_score = score
            if self.restore_best_weights:
                self.best_weights = {k: v.clone() for k, v in model.state_dict().items()}
        elif self.compare(score, self.best_score + self.min_delta):
            self.best_score = score
            self.counter = 0
            if self.restore_best_weights:
                self.best_weights = {k: v.clone() for k, v in model.state_dict().items()}
        else:
            self.counter += 1

        if self.counter >= self.patience:
            self.early_stop = True
            if self.restore_best_weights and self.best_weights is not None:
                model.load_state_dict(self.best_weights)

        return self.early_stop


class MetricsTracker:
    """
    üìà –¢–†–ï–ö–ï–† –ú–ï–¢–†–ò–ö

    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    """

    def __init__(self):
        self.metrics_history = {}
        self.start_time = time.time()

    def update(self, metrics: Dict[str, float], step: int = None):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫"""
        for name, value in metrics.items():
            if name not in self.metrics_history:
                self.metrics_history[name] = []
            self.metrics_history[name].append({
                'step': step,
                'value': value,
                'timestamp': time.time() - self.start_time
            })

    def get_latest(self, metric_name: str) -> Optional[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏"""
        if metric_name in self.metrics_history and self.metrics_history[metric_name]:
            return self.metrics_history[metric_name][-1]['value']
        return None

    def get_trend(self, metric_name: str, window: int = 5) -> str:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ –º–µ—Ç—Ä–∏–∫–∏"""
        if metric_name not in self.metrics_history or len(self.metrics_history[metric_name]) < window:
            return "insufficient_data"

        recent_values = [entry['value'] for entry in self.metrics_history[metric_name][-window:]]
        if len(recent_values) < 2:
            return "stable"

        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
        slope = np.polyfit(range(len(recent_values)), recent_values, 1)[0]

        if abs(slope) < 0.001:
            return "stable"
        elif slope > 0:
            return "increasing" if metric_name != 'loss' else "worsening"
        else:
            return "decreasing" if metric_name != 'loss' else "improving"

    def get_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º"""
        summary = {}
        for name, history in self.metrics_history.items():
            if history:
                values = [entry['value'] for entry in history]
                summary[name] = {
                    'current': values[-1],
                    'best': min(values) if 'loss' in name else max(values),
                    'worst': max(values) if 'loss' in name else min(values),
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'trend': self.get_trend(name)
                }
        return summary


class AdvancedModelTrainer:
    """
    üèãÔ∏è‚Äç‚ôÇÔ∏è –ü–†–û–î–í–ò–ù–£–¢–´–ô –¢–†–ï–ù–ï–† –ú–û–î–ï–õ–ò

    –ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å:
    - –ì–∏–±–∫–∏–º–∏ callbacks –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    - Early stopping –∏ learning rate scheduling
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
    - –ü–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º
    """

    def __init__(self, 
                 model: nn.Module,
                 optimizer: Optimizer,
                 config: ModelConfig,
                 scheduler: Optional[_LRScheduler] = None,
                 early_stopping: Optional[EarlyStopping] = None,
                 checkpoint_dir: Optional[str] = None):
        """
        Args:
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            optimizer: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
            scheduler: Learning rate scheduler
            early_stopping: Early stopping —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
            checkpoint_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        """
        self.model = model
        self.optimizer = optimizer
        self.config = config
        self.scheduler = scheduler
        self.early_stopping = early_stopping or EarlyStopping(patience=10)

        self.logger = GenerationLogger()
        self.metrics_tracker = MetricsTracker()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        if checkpoint_dir:
            self.checkpoint_dir = Path(checkpoint_dir)
            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        else:
            self.checkpoint_dir = None

        # –°—á–µ—Ç—á–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.step = 0
        self.epoch = 0
        self.tokens_processed = 0
        self.training_start_time = None

    def train_step(self, data: torch.Tensor) -> Dict[str, float]:
        """
        üîÑ –ü–†–û–î–í–ò–ù–£–¢–´–ô –®–ê–ì –û–ë–£–ß–ï–ù–ò–Ø

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —à–∞–≥–∞
        """
        step_start_time = time.time()

        # –ü–æ–ª—É—á–∞–µ–º –±–∞—Ç—á
        xb, yb = get_batch(data, self.config, "train")
        batch_size, seq_len = xb.shape

        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
        self.model.train()
        logits, loss = self.model(xb, yb)

        # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
        self.optimizer.zero_grad(set_to_none=True)
        loss.backward()

        # Gradient clipping (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if hasattr(self.config, 'gradient_clip_val') and self.config.gradient_clip_val > 0:
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.gradient_clip_val)

        self.optimizer.step()

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ scheduler
        if self.scheduler:
            self.scheduler.step()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        step_time = time.time() - step_start_time
        tokens_in_batch = batch_size * seq_len
        self.tokens_processed += tokens_in_batch

        # –ú–µ—Ç—Ä–∏–∫–∏ —à–∞–≥–∞
        step_metrics = {
            'train_loss': loss.item(),
            'learning_rate': self.optimizer.param_groups[0]['lr'],
            'step_time': step_time,
            'tokens_per_second': tokens_in_batch / step_time,
            'batch_size': batch_size,
            'sequence_length': seq_len
        }

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if hasattr(self.config, 'compute_additional_metrics') and self.config.compute_additional_metrics:
            step_metrics.update(self._compute_additional_metrics(logits, yb))

        self.step += 1
        return step_metrics

    def _compute_additional_metrics(self, logits: torch.Tensor, targets: torch.Tensor) -> Dict[str, float]:
        """üìä –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        with torch.no_grad():
            # Accuracy
            predictions = torch.argmax(logits, dim=-1)
            accuracy = (predictions == targets).float().mean().item()

            # Perplexity
            loss_unreduced = nn.functional.cross_entropy(
                logits.view(-1, logits.size(-1)), 
                targets.view(-1), 
                reduction='none'
            )
            perplexity = torch.exp(loss_unreduced.mean()).item()

            return {
                'accuracy': accuracy,
                'perplexity': perplexity
            }

    def evaluate(self, data: torch.Tensor, 
                splits: List[str] = None) -> Dict[str, float]:
        """
        üìä –ü–†–û–î–í–ò–ù–£–¢–ê–Ø –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò

        Returns:
            –ü–æ–¥—Ä–æ–±–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Å–µ–º split'–∞–º
        """
        eval_start_time = time.time()

        # –ë–∞–∑–æ–≤—ã–µ loss'—ã
        losses = estimate_loss(self.model, data, self.config, splits)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ float –∏ –¥–æ–±–∞–≤–ª—è–µ–º perplexity
        eval_metrics = {}
        for split, loss_tensor in losses.items():
            loss_val = loss_tensor.item()
            eval_metrics[f'{split}_loss'] = loss_val
            eval_metrics[f'{split}_perplexity'] = calculate_perplexity(loss_val)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if 'train' in losses and 'val' in losses:
            train_loss = losses['train'].item()
            val_loss = losses['val'].item()
            eval_metrics['overfit_indicator'] = val_loss - train_loss
            eval_metrics['generalization_gap'] = val_loss / train_loss if train_loss > 0 else float('inf')

        eval_metrics['eval_time'] = time.time() - eval_start_time

        return eval_metrics

    def save_checkpoint(self, 
                       filepath: Optional[str] = None, 
                       include_optimizer: bool = True) -> str:
        """üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
        if self.checkpoint_dir is None and filepath is None:
            raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")

        if filepath is None:
            filepath = self.checkpoint_dir / f"checkpoint_epoch_{self.epoch}_step_{self.step}.pt"

        checkpoint_data = {
            'epoch': self.epoch,
            'step': self.step,
            'model_state_dict': self.model.state_dict(),
            'config': self.config,
            'metrics_history': self.metrics_tracker.metrics_history,
            'tokens_processed': self.tokens_processed
        }

        if include_optimizer:
            checkpoint_data['optimizer_state_dict'] = self.optimizer.state_dict()
            if self.scheduler:
                checkpoint_data['scheduler_state_dict'] = self.scheduler.state_dict()

        torch.save(checkpoint_data, filepath)
        self.logger.logger.info(f"üíæ –ß–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}")

        return str(filepath)

    def load_checkpoint(self, filepath: str, load_optimizer: bool = True) -> Dict[str, Any]:
        """üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
        checkpoint = torch.load(filepath, map_location=self.config.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.epoch = checkpoint.get('epoch', 0)
        self.step = checkpoint.get('step', 0)
        self.tokens_processed = checkpoint.get('tokens_processed', 0)

        if load_optimizer and 'optimizer_state_dict' in checkpoint:
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

            if self.scheduler and 'scheduler_state_dict' in checkpoint:
                self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –º–µ—Ç—Ä–∏–∫
        if 'metrics_history' in checkpoint:
            self.metrics_tracker.metrics_history = checkpoint['metrics_history']

        self.logger.logger.info(f"üìÅ –ß–µ–∫–ø–æ–∏–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {filepath}")
        return checkpoint

    def train_epoch(self, 
                   data: torch.Tensor,
                   callback: Optional[Callable] = None,
                   save_checkpoints: bool = False,
                   checkpoint_freq: int = 500) -> Dict[str, Any]:
        """
        üöÄ –ü–û–õ–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –≠–ü–û–•–ò

        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            callback: –§—É–Ω–∫—Ü–∏—è callback –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            save_checkpoints: –°–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã
            checkpoint_freq: –ß–∞—Å—Ç–æ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤

        Returns:
            –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """

        if self.training_start_time is None:
            self.training_start_time = time.time()

        self.epoch += 1
        epoch_start_time = time.time()

        self.logger.logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —ç–ø–æ—Ö–∏ {self.epoch}")

        # –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫ —ç–ø–æ—Ö–∏
        epoch_train_losses = []

        for iter_num in range(self.config.max_iters):

            # –®–∞–≥ –æ–±—É—á–µ–Ω–∏—è
            step_metrics = self.train_step(data)
            epoch_train_losses.append(step_metrics['train_loss'])

            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–∫–µ—Ä –º–µ—Ç—Ä–∏–∫
            self.metrics_tracker.update(step_metrics, self.step)

            # –û—Ü–µ–Ω–∫–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if iter_num % self.config.eval_interval == 0:

                # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
                eval_metrics = self.evaluate(data)

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                combined_metrics = {**step_metrics, **eval_metrics}

                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–∫–µ—Ä
                self.metrics_tracker.update(eval_metrics, self.step)

                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                val_loss = eval_metrics.get('val_loss', float('inf'))
                train_loss = step_metrics['train_loss']

                self.logger.logger.info(
                    f"üìä Step {iter_num}: "
                    f"train_loss={train_loss:.4f} "
                    f"val_loss={val_loss:.4f} "
                    f"lr={step_metrics['learning_rate']:.2e} "
                    f"tokens/s={step_metrics['tokens_per_second']:.0f}"
                )

                # Callback –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (MLflow)
                if callback:
                    try:
                        callback(iter_num, combined_metrics)
                    except Exception as e:
                        self.logger.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ callback: {e}")

                # Early stopping
                if self.early_stopping and self.early_stopping(val_loss, self.model):
                    self.logger.logger.info(f"‚èπÔ∏è Early stopping –Ω–∞ —à–∞–≥–µ {iter_num}")

                    return {
                        'early_stopped_at': iter_num,
                        'final_metrics': combined_metrics,
                        'epoch_losses': epoch_train_losses,
                        'metrics_summary': self.metrics_tracker.get_summary(),
                        'total_tokens_processed': self.tokens_processed,
                        'training_time': time.time() - epoch_start_time
                    }

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
            if save_checkpoints and self.checkpoint_dir and (iter_num + 1) % checkpoint_freq == 0:
                self.save_checkpoint()

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        final_metrics = self.evaluate(data)

        training_time = time.time() - epoch_start_time
        total_training_time = time.time() - self.training_start_time

        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–ø–æ—Ö–∏
        self.logger.logger.info(f"‚úÖ –≠–ø–æ—Ö–∞ {self.epoch} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {training_time:.1f}—Å")
        self.logger.logger.info(f"üìà –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {final_metrics}")

        return {
            'final_metrics': final_metrics,
            'epoch_losses': epoch_train_losses,
            'metrics_summary': self.metrics_tracker.get_summary(),
            'total_tokens_processed': self.tokens_processed,
            'epoch_training_time': training_time,
            'total_training_time': total_training_time,
            'tokens_per_second_avg': self.tokens_processed / total_training_time
        }


# üîÑ –û–ë–†–ê–¢–ù–ê–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨ –° –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ú –ö–û–î–û–ú
class ModelTrainer:
    """–ü—Ä–æ—Å—Ç–æ–π —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""

    def __init__(self, model, optimizer, config: ModelConfig):
        self.model = model
        self.optimizer = optimizer
        self.config = config
        self.losses_val = []
        self.step = 0

    def train_step(self, data: torch.Tensor) -> float:
        """–û–¥–∏–Ω —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è"""
        xb, yb = get_batch(data, self.config, "train")
        logits, loss = self.model(xb, yb)

        self.optimizer.zero_grad(set_to_none=True)
        loss.backward()
        self.optimizer.step()

        return loss.item()

    def evaluate(self, data: torch.Tensor) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
        losses = estimate_loss(self.model, data, self.config)
        return {k: v.item() for k, v in losses.items()}

    def should_early_stop(self, val_loss: float) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏—è —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∞"""
        self.losses_val.append(val_loss)

        if len(self.losses_val) >= 2:
            return self.losses_val[-1] - self.losses_val[-2] > self.config.overfit_line

        return False

    def train_epoch(self, data: torch.Tensor, callback=None) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏"""
        self.model.train()
        epoch_losses = []

        for iter_num in range(self.config.max_iters):
            # –®–∞–≥ –æ–±—É—á–µ–Ω–∏—è
            loss = self.train_step(data)
            epoch_losses.append(loss)

            # –û—Ü–µ–Ω–∫–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if iter_num % self.config.eval_interval == 0:
                eval_losses = self.evaluate(data)

                print(f"step {iter_num}: train loss {eval_losses['train']:.4f} val loss {eval_losses['val']:.4f}")

                # –í—ã–∑—ã–≤–∞–µ–º callback –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                if callback:
                    callback(iter_num, eval_losses)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
                if self.should_early_stop(eval_losses['val']):
                    print(f"Early stopping at iteration {iter_num}")
                    return {
                        'early_stopped_at': iter_num,
                        'final_losses': eval_losses,
                        'epoch_losses': epoch_losses
                    }

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        final_losses = self.evaluate(data)

        return {
            'final_losses': final_losses,
            'epoch_losses': epoch_losses
        }