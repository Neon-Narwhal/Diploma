"""Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸"""

import torch
from typing import Tuple
from utils.config import ModelConfig
import json


def load_data(file_path: str) -> str:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()

    except FileNotFoundError:
        print(f"Ğ¤Ğ°Ğ¹Ğ» {file_path} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.")
        return "Hello world! This is a test dataset for training language models. " * 100
    
def load_data_json(file_path: str, sample_size: int = -1) -> list:
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ° Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ¼ jsonl"""
    datas = []
    
    with open(file_path, 'r', encoding='utf-8') as file:
        for line in file:
            if sample_size == 0:
                break
            
            line = line.strip()
            if not line:
                continue
                
            try:
                datas.append(json.loads(line))
                sample_size = sample_size - 1 if sample_size > 0 else -1
            except json.JSONDecodeError as e:
                print(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° ÑÑ‚Ñ€Ğ¾ĞºĞ¸: {line}")
                print(e)
    
    return datas
    

def get_batch(data: torch.Tensor, config: ModelConfig, split: str = "train") -> Tuple[torch.Tensor, torch.Tensor]:
    """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ±Ğ°Ñ‚Ñ‡Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ"""
    n = int(0.9 * len(data))
    train_data = data[:n] if split == "train" else data[n:]
    
    ix = torch.randint(len(train_data) - config.block_size, (config.batch_size,))
    x = torch.stack([train_data[i:i + config.block_size] for i in ix])
    y = torch.stack([train_data[i + 1:i + config.block_size + 1] for i in ix])
    x, y = x.to(config.device), y.to(config.device)
    return x, y


def prepare_data(text: str, tokenizer, config: ModelConfig, split_flag: bool = False) -> torch.Tensor:
    """
    ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
    
    Args:
        text: Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚
        tokenizer: Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°
        config: ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        
    Returns:
        torch.Tensor: Ğ¢ĞµĞ½Ğ·Ğ¾Ñ€ Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
    """
    # Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
    encoded_data = tokenizer.encode(text)
    data_tensor = torch.tensor(encoded_data, dtype=torch.long)
    

    print(f"ğŸ“Š ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ:")
    print(f"   - Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚: {len(text):,} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")  
    print(f"   - Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {len(encoded_data):,}")
    print(f"   - Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ°: {data_tensor.shape}")
    print(f"   - Ğ£ÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾: {config.device}")
    print(f"   - Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {len(encoded_data)/len(text):.3f} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²/ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»")
    
    if split_flag:
        n = int(config.train_val_split * len(data_tensor))
        return data_tensor[:n], data_tensor[n:]  
    
    return data_tensor   

def split_data(data: torch.Tensor, train_val_split: float) -> tuple[torch.Tensor, torch.Tensor]:
    n = int(train_val_split * len(data))
    return data[:n], data[n:]

