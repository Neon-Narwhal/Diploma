"""–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏"""

import torch
from typing import Tuple
from utils.config import ModelConfig


def load_data(file_path: str) -> str:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        return "Hello world! This is a test dataset for training language models. " * 100


def get_batch(data: torch.Tensor, config: ModelConfig, split: str = "train") -> Tuple[torch.Tensor, torch.Tensor]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    n = int(0.9 * len(data))
    train_data = data[:n] if split == "train" else data[n:]
    
    ix = torch.randint(len(train_data) - config.block_size, (config.batch_size,))
    x = torch.stack([train_data[i:i + config.block_size] for i in ix])
    y = torch.stack([train_data[i + 1:i + config.block_size + 1] for i in ix])
    x, y = x.to(config.device), y.to(config.device)
    return x, y


def prepare_data(text: str, tokenizer, config: ModelConfig) -> torch.Tensor:
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        tokenizer: –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        
    Returns:
        torch.Tensor: –¢–µ–Ω–∑–æ—Ä —Å —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
    encoded_data = tokenizer.encode(text)
    data_tensor = torch.tensor(encoded_data, dtype=torch.long)
    
    print(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ:")
    print(f"   - –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(text):,} —Å–∏–º–≤–æ–ª–æ–≤")  
    print(f"   - –¢–æ–∫–µ–Ω–æ–≤: {len(encoded_data):,}")
    print(f"   - –†–∞–∑–º–µ—Ä —Ç–µ–Ω–∑–æ—Ä–∞: {data_tensor.shape}")
    print(f"   - –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {config.device}")
    print(f"   - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏: {len(encoded_data)/len(text):.3f} —Ç–æ–∫–µ–Ω–æ–≤/—Å–∏–º–≤–æ–ª")
    
    return data_tensor
