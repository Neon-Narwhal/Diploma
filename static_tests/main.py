"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞.
–í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –∏–∑ config.py
"""

from pathlib import Path
import logging
from typing import Optional, List

from dataset_processor import DatasetProcessor
from config import (
    TOOLS_REGISTRY,
    DEFAULT_PYTHON_DATASET,
    DEFAULT_JAVA_DATASET,
    RESULTS_DIR,
    DATA_DIR,
    ComplexityClass,
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    INPUT_FILE,
    OUTPUT_DIR,
    TOOLS_TO_RUN,
    MAX_SAMPLES,
    LANGUAGE
)


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def run_analysis(
    input_path: Optional[Path] = None,
    output_dir: Optional[Path] = None,
    tools: Optional[List[str]] = None,
    max_samples: Optional[int] = None,
    language: str = 'python'
) -> dict:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
    
    Args:
        input_path: –ü—É—Ç—å –∫ JSONL —Ñ–∞–π–ª—É. –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è DEFAULT_PYTHON_DATASET
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è RESULTS_DIR
        tools: –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è. –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ –≤–∫–ª—é—á–µ–Ω–Ω—ã–µ
        max_samples: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        language: –Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ('python' –∏–ª–∏ 'java')
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
    if input_path is None:
        if language.lower() == 'python':
            input_path = DEFAULT_PYTHON_DATASET
        elif language.lower() == 'java':
            input_path = DEFAULT_JAVA_DATASET
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —è–∑—ã–∫: {language}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'python' –∏–ª–∏ 'java'")
        
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞—Å–µ—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {input_path}")
    else:
        input_path = Path(input_path)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if output_dir is None:
        output_dir = RESULTS_DIR / language.lower()
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {output_dir}")
    else:
        output_dir = Path(output_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not input_path.exists():
        logger.error(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        logger.info(f"–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ {DATA_DIR}")
        logger.info(f"–û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:")
        logger.info(f"  project_root/")
        logger.info(f"  ‚îú‚îÄ‚îÄ complexity_analyzer/")
        logger.info(f"  ‚îî‚îÄ‚îÄ data/")
        logger.info(f"      ‚îî‚îÄ‚îÄ {input_path.name}")
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
    
    if tools is None:
        from config import TOOLS_TO_RUN
        tools = TOOLS_TO_RUN
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = DatasetProcessor(tools_to_use=tools)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    logger.info("–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    results = processor.process_dataset(
        filepath=input_path,
        output_dir=output_dir,
        max_samples=max_samples
    )
    
    logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_dir}")
    
    # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n" + "="*80)
    print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*80)
    
    for tool_name, tool_results in results.items():
        metrics = tool_results['metrics']
        time_stats = tool_results['time_statistics']
        
        print(f"\n{'='*80}")
        print(f"{tool_name.upper()}")
        print(f"{'='*80}")
        
        print(f"\nüìä –ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê:")
        print(f"  Accuracy:              {metrics['accuracy']:.4f}")
        print(f"  F1 (weighted):         {metrics['f1_weighted']:.4f}")
        print(f"  Precision (weighted):  {metrics['precision_weighted']:.4f}")
        print(f"  Recall (weighted):     {metrics['recall_weighted']:.4f}")
        print(f"  –í–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {tool_results['valid_predictions']}/{tool_results['total_samples']}")
        
        print(f"\n‚è±Ô∏è  –í–†–ï–ú–ï–ù–ù–´–ï –ú–ï–¢–†–ò–ö–ò:")
        print(f"  –û–±—â–µ–µ –≤—Ä–µ–º—è:           {time_stats['total_execution_time']:.2f} —Å–µ–∫")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è/–æ–±—Ä–∞–∑–µ—Ü: {time_stats['mean_time_per_sample']*1000:.2f} –º—Å")
        print(f"  –ú–µ–¥–∏–∞–Ω–∞ –≤—Ä–µ–º—è/–æ–±—Ä–∞–∑–µ—Ü: {time_stats['median_time_per_sample']*1000:.2f} –º—Å")
        print(f"  –ú–∏–Ω –≤—Ä–µ–º—è/–æ–±—Ä–∞–∑–µ—Ü:     {time_stats['min_time_per_sample']*1000:.2f} –º—Å")
        print(f"  –ú–∞–∫—Å –≤—Ä–µ–º—è/–æ–±—Ä–∞–∑–µ—Ü:    {time_stats['max_time_per_sample']*1000:.2f} –º—Å")
        print(f"  –û–±—Ä–∞–∑—Ü–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É:    {time_stats['samples_per_second']:.2f}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º –∞—Å–∏–º–ø—Ç–æ—Ç–∏–∫–∏
        print(f"\nüéØ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ö–õ–ê–°–°–ê–ú –ê–°–ò–ú–ü–¢–û–¢–ò–ö–ò:")
        class_dist = tool_results['class_distribution']
        
        print(f"\n{'–ö–ª–∞—Å—Å':<12} {'–ò—Å—Ç–∏–Ω–Ω—ã—Ö':<10} {'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ':<12} {'–ü—Ä–∞–≤–∏–ª—å–Ω–æ':<10} {'–¢–æ—á–Ω–æ—Å—Ç—å':<10}")
        print("-" * 80)
        
        for complexity_class in [c.value for c in ComplexityClass]:
            if complexity_class in class_dist:
                dist = class_dist[complexity_class]
                print(
                    f"{complexity_class:<12} "
                    f"{dist['true_count']:<10} "
                    f"{dist['predicted_count']:<12} "
                    f"{dist['correct_predictions']:<10} "
                    f"{dist['accuracy_for_class']:.1f}%"
                )
    
    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏
    if len(results) > 1:
        print("\n" + "="*80)
        print("–°–†–ê–í–ù–ï–ù–ò–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–û–í –ü–û –°–ö–û–†–û–°–¢–ò")
        print("="*80)
        print(f"{'–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç':<15} {'–û–±—â–µ–µ –≤—Ä–µ–º—è':<15} {'–°—Ä–µ–¥. –≤—Ä–µ–º—è':<15} {'–û–±—Ä–∞–∑—Ü–æ–≤/—Å–µ–∫':<15}")
        print("-" * 80)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É –≤—Ä–µ–º–µ–Ω–∏
        sorted_tools = sorted(
            results.items(),
            key=lambda x: x[1]['time_statistics']['mean_time_per_sample']
        )
        
        for tool_name, tool_results in sorted_tools:
            time_stats = tool_results['time_statistics']
            print(
                f"{tool_name:<15} "
                f"{time_stats['total_execution_time']:>12.2f} s  "
                f"{time_stats['mean_time_per_sample']*1000:>12.2f} ms "
                f"{time_stats['samples_per_second']:>14.2f}"
            )
    
    return results


def main():
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–∑ config.py
    """
    print("="*80)
    print("–ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –°–õ–û–ñ–ù–û–°–¢–ò –ö–û–î–ê")
    print("="*80)
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config.py:")
    print(f"  –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª:     {INPUT_FILE or '–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é'}")
    print(f"  –í—ã—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞:   {OUTPUT_DIR or '–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é'}")
    print(f"  –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:      {TOOLS_TO_RUN or '–≤—Å–µ –≤–∫–ª—é—á–µ–Ω–Ω—ã–µ'}")
    print(f"  –ú–∞–∫—Å. –æ–±—Ä–∞–∑—Ü–æ–≤:   {MAX_SAMPLES or '–≤—Å–µ'}")
    print(f"  –Ø–∑—ã–∫:             {LANGUAGE}")
    print("="*80)
    print()
    
    try:
        run_analysis(
            input_path=INPUT_FILE,
            output_dir="static_tests/results/results_advenced",
            tools=TOOLS_TO_RUN,
            max_samples=MAX_SAMPLES,
            language=LANGUAGE
        )
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except FileNotFoundError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        print(f"\nüí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫:")
        print(f"   project_root/")
        print(f"   ‚îú‚îÄ‚îÄ complexity_analyzer/")
        print(f"   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py")
        print(f"   ‚îÇ   ‚îú‚îÄ‚îÄ config.py")
        print(f"   ‚îÇ   ‚îî‚îÄ‚îÄ ...")
        print(f"   ‚îú‚îÄ‚îÄ data/")
        print(f"   ‚îÇ   ‚îî‚îÄ‚îÄ python_dataset.jsonl")
        print(f"   ‚îî‚îÄ‚îÄ run_analysis.py")
        
    except Exception as e:
        print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == '__main__':
    main()
